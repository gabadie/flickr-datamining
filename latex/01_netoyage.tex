\chapter{Chargement et nettoyage des données}

\section{Prototypage et découverte des données}
    % TODO : Garder cette partie ici, ou faire un chapitre préliminaire où on %
    % parle du fait d'utiliser Knime puis de passer sur python ?              %
    Nous avons dans un premier temps utilisé Knime pour exploiter la base de données,
    et tester les algorithmes des clustering.

    Pour cela, nous avons d'abord configuré le nœud de lecture de fichiers CSV~: choix du
    séparateur de colonnes (tabulation, dans notre cas), autorisation des \textit{shortlines},
    gestion des valeurs manquantes, ...

\section{Types des données}
    Nous avions des types parasites dans les données. En effet nous
    avions des colonnes considérées comme ``String'' alors qu'elles étaient
    censées être des ``Double''. Ceci est dû à des valeurs parasites (la fameuse
    valeur de latitude ``trolilol'', notamment).

\section{Unicité des valeurs}
    Nous avions aussi détecté des problèmes d'unicité des valeurs. Par
    exemple, il apparaît que l'ID des photos n'est pas unique.
    Ceci peut être dû au fait que la récupération (\textit{scrapping}) de telles données
    se fait souvent de manière parallélisée, et qu'une même photo peut ainsi être récupérées plusieurs fois.

    En partant de l'hypothèse que ces duplicatas représentent les mêmes
    informations, on peut arbitrairement garder un élément par id de photo.

    Une deuxième solution, plus rigoureuse, est de créer un nouvel id garantissant
    l'unicité des informations (c'est à dire l'ensemble des colonnes pertinentes: id de
    la photo, id de l'utilisateur, date, tags et légende). C'est cette solution que nous avons choisi d'appliquer.

\section{Validité des données}
    L'élimination des duplicatas et la vérification du type des données ne suffit pas à garantir la validité de ces dernières.

    Par exemple, bien que l'année de prise d'une photo soit un entier, il est bien possible que
    celle ci soit incohérente (pour de multiples raisons: corruption de données, troll d'enseignants, etc.) et
    altère la valorisation des données (par exemple en perturbant le clustering).

    Par exemple une photo prise en 1780, avant l'invention de l'appareil photo ou
    bien une photo ayant été prise... dans 10 ans !

    Ces valeurs incohérentes peuvent parfois être conservées, ou être ``corrigées'' en les remplaçant par une moyenne globale (ou locale,
    calculée sur les éléments semblables). Dans notre cas, nous avons choisi d'éliminer les photos présentant des incohérences au vu de
    l'amplitude de celles ci, et du faible nombre de photos concernées.

    Voici les critères de validité retenus~:

    \subsection{Année de la prise de la photo}
        Ainsi, nous avons décidé de filtrer tout les photos ayant été prises
        avant l'an 2000 ou dans le futur.

        \begin{figure}[h]
            \centering
            \includegraphics[scale=0.35]{../screenshots/year_id_before.png}
            \caption{données avant filtrage}
            \label{diagram:year_id_before}
        \end{figure}

        \begin{figure}[h]
            \centering
            \includegraphics[scale=0.35]{../screenshots/year_id_after.png}
            \caption{données apr\`es filtrage}
            \label{diagram:year_id_after}
        \end{figure}

    \pagebreak
    \subsection{Mois et jour}

        Nous n'avons pas poussé la validation jusqu'à vérifier que la chaque jour ne dépassait pas la longueur de chaque mois, mais nous avons décidé d'éliminer toutes les photos prises à un jour > 31 (ou < 1) et les mois > 12 (ou < 1).

        \begin{figure}[h]
            \centering
            \includegraphics[scale=0.35]{../screenshots/month_day_before.png}
            \caption{données avant filtrage}
            \label{diagram:month_day_before}
        \end{figure}

        \begin{figure}[h]
            \centering
            \includegraphics[scale=0.35]{../screenshots/month_day_after.png}
            \caption{données apr\`es filtrage}
            \label{diagram:month_day_after}
        \end{figure}

    \pagebreak
    \subsection{Jour et heure}

        On aimerait tous que les jours fassent plus de 24 heures, mais pour ce projet là nous avons malgré tout éliminé les valeurs plus grandes que 23.

        \begin{figure}[h]
            \centering
            \includegraphics[scale=0.27]{../screenshots/day_hour_before.png}
            \caption{données avant filtrage}
            \label{diagram:day_hour_before}
        \end{figure}

        \begin{figure}[h]
            \centering
            \includegraphics[scale=0.35]{../screenshots/day_hour_after.png}
            \caption{données apr\`es filtrage}
            \label{diagram:day_hour_after}
        \end{figure}

    \pagebreak
    \subsection{Coordonnées GPS}

        Probablement pour des raisons de conversion (ou de troll pur et simple de la part de notre source de données),
        un point était situé aux coordonnées (0, 0). Nous avons donc préféré éliminer ce point individuellement au lieu
        de restreindre les valeurs de latitude et de longitude (de ce fait, nous avons aussi gardés des points éloignés
        du centre de Lyon, mais pertinents dans notre étude)

        \begin{figure}[h]
            \centering
            \includegraphics[scale=0.22]{../screenshots/geographic_before.png}
            \caption{Coordonnées GPS avant filtrage}
            \label{diagram:geographic_before}
        \end{figure}

        \begin{figure}[h]
            \centering
            \includegraphics[scale=0.22]{../screenshots/geographic_after.png}
            \caption{Coordonnées GPS apr\`es filtrage}
            \label{diagram:geographic_after}
        \end{figure}
